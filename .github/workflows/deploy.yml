name: Final Demo â€“ Governed Lakehouse CI/CD

on:
  push:
    branches: [ "main" ]
  workflow_dispatch:

env:
  AWS_REGION: us-east-1
  TF_WORKING_DIR: infra
  S3_DEMO_PREFIX: final-demo

jobs:
  deploy:
    runs-on: ubuntu-latest

    steps:
      # ======================================================
      # 1) Checkout
      # ======================================================
      - name: Checkout code
        uses: actions/checkout@v4

      # ======================================================
      # 2) AWS Credentials
      # ======================================================
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id:     ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region:            ${{ env.AWS_REGION }}

      # ======================================================
      # 3) Debug (so path issues never happen again)
      # ======================================================
      - name: Debug repo folders
        run: |
          echo "=== Repo root ==="
          ls -la
          echo "=== Find python files (top 4 levels) ==="
          find . -maxdepth 4 -type f -name "*.py" | sed -e 's|^\./||' | head -n 200
          echo "=== Find SQL files (top 5 levels) ==="
          find . -maxdepth 5 -type f -name "*.sql" | sed -e 's|^\./||' | head -n 200

      # ======================================================
      # 4) Upload Glue scripts to S3
      #    Your repo has: glue/*.py (from your screenshot)
      # ======================================================
      - name: Upload Athena SQL to S3 (auto-detect)
        run: |
          echo "Searching for Athena ddl folder..."
          SQL_DIR=$(find . -type d -path "*/athena/ddl" | head -n 1)

          if [ -z "$SQL_DIR" ]; then
            echo "ERROR: Could not find any */athena/ddl folder in repo."
            echo "Folders under repo root:"
            find . -maxdepth 3 -type d | sed -e 's|^\./||'
            exit 1
          fi

          echo "Found SQL folder: $SQL_DIR"
          aws s3 sync "$SQL_DIR" \
            s3://${{ secrets.DEMO_BUCKET }}/${{ env.S3_DEMO_PREFIX }}/sql \
            --delete \
            --region $AWS_REGION



      # ======================================================
      # 5) Upload Athena SQL to S3
      #    Your repo has: athena/ddl/*.sql (from your screenshot)
      # ======================================================
      - name: Upload Athena SQL to S3
        run: |
          if [ ! -d "athena/ddl" ]; then
            echo "ERROR: athena/ddl folder not found at repo root."
            exit 1
          fi

          aws s3 sync athena/ddl \
            s3://${{ secrets.DEMO_BUCKET }}/${{ env.S3_DEMO_PREFIX }}/sql \
            --delete \
            --region $AWS_REGION

      # ======================================================
      # 6) Terraform
      # ======================================================
      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3

      - name: Terraform Init
        working-directory: ${{ env.TF_WORKING_DIR }}
        run: terraform init

      - name: Terraform Validate
        working-directory: ${{ env.TF_WORKING_DIR }}
        run: terraform validate

      - name: Terraform Apply
        working-directory: ${{ env.TF_WORKING_DIR }}
        run: |
          terraform apply -auto-approve \
            -var="aws_region=${{ env.AWS_REGION }}" \
            -var="account_id=${{ secrets.ACCOUNT_ID }}" \
            -var="bucket=${{ secrets.DEMO_BUCKET }}" \
            -var="scripts_prefix=${{ env.S3_DEMO_PREFIX }}/scripts" \
            -var="sql_prefix=${{ env.S3_DEMO_PREFIX }}/sql" \
            -var="glue_role_arn=${{ secrets.GLUE_ROLE_ARN }}" \
            -var="athena_workgroup=nyc-governed-wg" \
            -var="athena_results_s3=s3://${{ secrets.DEMO_BUCKET }}/athena_results/" \
            -var="athena_db_master=nyc_master_db" \
            -var="athena_db_curated=nyc_curated_db" \
            -var="redshift_secret_name=nyc/redshift/admin" \
            -var="redshift_iam_role_arn=${{ secrets.REDSHIFT_IAM_ROLE_ARN }}" \
            -var="redshift_db=dev"

      # ======================================================
      # 7) OPTIONAL: Auto-run the pipeline after deploy
      # ======================================================
      # ======================================================
      # OPTIONAL: Auto-run the pipeline after deploy
      # ======================================================
      - name: Start Step Functions execution
        env:
          AUTO_RUN: ${{ secrets.AUTO_RUN }}
        if: ${{ env.AUTO_RUN == 'true' }}
        run: |
          SFN_ARN=$(aws stepfunctions list-state-machines \
            --query "stateMachines[?name=='final-demo-governed-lakehouse'].stateMachineArn | [0]" \
            --output text \
            --region $AWS_REGION)

          if [ "$SFN_ARN" = "None" ] || [ -z "$SFN_ARN" ]; then
            echo "ERROR: Could not find Step Function final-demo-governed-lakehouse"
            exit 1
          fi

          echo "Starting execution: $SFN_ARN"
          aws stepfunctions start-execution \
            --state-machine-arn "$SFN_ARN" \
            --input file://stepfunctions/payloads/run_input.dev.json \
            --region $AWS_REGION
